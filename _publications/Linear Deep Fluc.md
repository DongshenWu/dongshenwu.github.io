---
title: "Linear Deep Fluctuations via Weight Perturbation for Post-hoc Out-of-distribution Detection"
collection: publications
# category: manuscripts
# permalink: /publication/linear-deep-fluctuations
excerpt: 'Abstract: A reliable uncertainty estimation method is the foundation of many modern out-of-distribution (OOD) detectors, which are critical for safe deployments of deep
learning models in the open world. In this work, we propose TULiP, a novel,
theoretically-driven, post-hoc uncertainty estimator for OOD detection. Our
method considers a hypothetical perturbation applied to the network prior to con-
vergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Compared to existing methods, our approach has a more versatile
backbone that can be extended to other problem settings. We verify our bound
empirically across regression and classification tasks. Furthermore, we demon-
strate the effectiveness of TULiP, which exhibits state-of-the-art performance in
real-world OOD detection benchmarks, particularly for near-distribution samples.'
date: 2025-03-01
venue: 'International Conference of Learning and Representation (ICLR)'
# slidesurl: 'http://academicpages.github.io/files/slides3.pdf'
# paperurl: 'http://academicpages.github.io/files/paper3.pdf'
# citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---

Abstract: A reliable uncertainty estimation method is the foundation of many modern out-
of-distribution (OOD) detectors, which are critical for safe deployments of deep
learning models in the open world. In this work, we propose TULiP, a novel,
theoretically-driven, post-hoc uncertainty estimator for OOD detection. Our
method considers a hypothetical perturbation applied to the network prior to con-
vergence. Based on linearized training dynamics, we bound the effect of such
perturbation, resulting in an uncertainty score computable by perturbing model
parameters. Compared to existing methods, our approach has a more versatile
backbone that can be extended to other problem settings. We verify our bound
empirically across regression and classification tasks. Furthermore, we demon-
strate the effectiveness of TULiP, which exhibits state-of-the-art performance in
real-world OOD detection benchmarks, particularly for near-distribution samples.